---
title: "Ensemble Model"
output: html_notebook
---
# Imports
```{r}
require(xgboost)
require(Matrix)
require(data.table)
require(caret)
require(mltools)
require(data.table)
require(progress)
require(modeest)
require(glmnet)
require(e1071)

```


# Math Data

## Data Intake
### Load Data
```{r}
df <- read.csv("data/math_data_cleaned.csv", header = TRUE)
drops <- c("X","G1","G2","G3", "Student_Score")
df <- df[ , !(names(df) %in% drops)]
```
### One Hot encoding
```{r}
Y <- df$Student_Class - 1

X <- df[,names(df) != "Student_Class"]
dtypes <- sapply(X, class)
categorical_names <- names(dtypes[dtypes != "integer"])
numerical_names <- names(dtypes[dtypes == "integer"])

categorical <- X[categorical_names]
numerical <- X[numerical_names]
categorical <- as.data.table(lapply(categorical, as.factor))
categorical <- one_hot(categorical)
X = cbind(categorical, numerical)

```

### Train-Test Split

```{r}
partition = createDataPartition(
  Y,
  times = 1,
  p = 0.7,
  list = TRUE,
  groups = min(5, length(Y))
)
X_train = X[partition$Resample1,]
X_test = X[-partition$Resample1,]

Y_train = Y[partition$Resample1]
Y_test = Y[-partition$Resample1]

```

## Logistic Regression
```{r}
lm_fit <- glmnet(as.matrix(X_train),as.factor(Y_train),lambda = 0.0447,alpha=1,family = "multinomial")
Y_hat_logistic <- predict(lm_fit,newx = as.matrix(X_test), s=0.0447,type = "class")
```

## XGBoost
### Train
```{r}
bstDense <- xgboost(data = as.matrix(X_train),
                    label= Y_train,
                    objective = "multi:softmax",
                    num_class = 3,
                    verbose = 0,
                    nrounds = 70,
                    eta = 0.01,
                    max_depth = 10,
                    min_child_weight = 1,
                    gamma = 0.1
                    )
```
### Predict on Test
```{r}
Y_hat_XGBoost <- as.factor(predict(bstDense, as.matrix(X_test)))
```

## SVM

```{r}
Y_train = factor(Y_train) 
train_data <- cbind.data.frame(X_train, Y_train)
Y_test = factor(Y_test) 
test_data <- cbind.data.frame(X_test, Y_test)

svm_data <- svm(train_data$Y_train~., data=train_data,kernel = "radial", cross = 5) 
Y_hat_SVM  = as.factor(predict(svm_data, newdata=X_test))


```


## Ensemble
```{r}
Y_hat_logistic <- as.factor(sample(0:2, length(Y_hat_XGBoost), replace = TRUE))
Y_hat_SVM <- as.factor(sample(0:2, length(Y_hat_XGBoost), replace = TRUE))
predictions <- data.frame(Y_hat_logistic, Y_hat_XGBoost, Y_hat_SVM)
class_chooser <- function(x){
  mode <- mlv(x, method = "mfv")
  if (length(mode) > 1) {
    mode <- sample(mode, 1)
  }
  mode <- factor(mode, levels = c("0","1","2"))
  return(mode)
}

end_predictions = apply(predictions, 1,class_chooser)

c_matrix <- confusionMatrix(data=end_predictions, reference = as.factor(Y_test))
c_matrix

```



## Evaluation
